\section{Method}

%\todo[inline]{Jeg ville gerne se det generelle udbygget lidt og ``kælet for''. }

\subsection{General model and the discrete motivation}
\label{sec:gen_model}
Our general model is that of a population-game \citep{kvrivan2009evolutionary} where the populations can migrate in a continuous habitat on a much faster time-scale than population dynamics \citep{cressman2006migration, abrams2007role}.

To understand the intrinsic coupling of patch-choice models with population dynamics,
consider a Lotka-Volterra model with $M$ patches and $T$ types. Assume the interactions of animals of type $i$ with type $j$ is given by a matrix $A_{ij}$, describing the inter-patch interactions. The intrinsic growth of type of $i$ at patch $k$ is given by $G_{i}(k)$. Assuming that the populations are distributed according to $(p_i)_{i=1}^N$ the population dynamics of type $i$ with total abundance $N_i$ become:
  \begin{equation}
  \dot{N}_i = N_i \sum_{k=1}^M p_i(k) \pa{\sum_{j=1}^T {(A_{ij}N_j) p_j}(k) + G_i(k)} %, ~i\neq
  \label{eq:pop_dyn_lv}
\end{equation}
%\todo[inline]{Udmærket generel formulering - men den skal lige poleres. Hvad med et konstant specifikt vækstled? Beskriver $N$ både antal arter og antal patches? Brug i øvrigt ikke $N$, da det også er abundancen. Brug ikke $A$ for både interaktionsmatricen og fitness. Jeg kan ikke gennemskue detaljerne i notationen ... }
%\todo[inline]{Konstant vækstled tilføjet, patches vs arter ryddet op. }
We define the fitness proxy for an individual by the individual growth rate:
%\todo{Jeg er ikke glad for at kalde en vækstrate for ``fitness''. Du bruger det vist i betydningen ``det der optimeres''. Men fitness defineres normalt som et individs forventede antal efterkommere. Brug evt. ``fitness proxy''.}
of an individual of type $i$ at patch $k$ by $F_i(k)$:
\begin{equation}
  F_i(\phi_i, (N_j \phi_j)_{j \leq T, j \neq i})(k) = p_i(k) \pa{\sum_{j=1}^T {A_{ij}N_j p_j}(k) + G_{i}(k)} %, ~i\neq
  \label{eq:utility_pm}
\end{equation}
If migrations are very fast and the habitat is highly interconnected \citep{abrams2007role, cressman2006migration}, it is reasonable to assume all animals of any type simultaneously seek to find the optimum patch in the sense of seeking $k$ to maximize \Cref{eq:utility_pm}. A population where every individual follows the optimal strategy for patch selection at any instant, that is finding $k$ to maximize \Cref{eq:utility_pm}, cannot be invaded by mutants following other strategies, so it constitutes an evolutionarily stable strategy \citep{kvrivan2009evolutionary}. The approach of using population dynamics determined by \Cref{eq:pop_dyn_lv} with optimal strategies determined by the Nash equilibrium defines a population game, and is a successful approach to coupling optimal behavior with population dynamics \citep{valdovinos2010consequences, mougi2019adaptive, pinti2021co}.

%The ideal free distribution is the resulting distribution  It arises from behavioral optimization in a multi-species Lotka-Volterra model with patches,


The system of utilities in \Cref{eq:utility_pm} can equivalently be interpreted as a polymatrix game \citep{howson1972equilibria}. This interpretation comes if we assume that individuals of type $i$ choose their positions randomly according to the distribution $(p_i)$, instead of having a fixed position $p_i(k)$, i.e. a monomorphic population rather than a polymorphic population. A polymatrix game has so-called polymorphic-monomorphic equivalence \citep{broom2013game}, so an individual of type $j$ cannot determine whether it is playing against a polymorphic population with pure strategies, or a monomorphic population with a mixed strategy. This insight is essential in generalizing to the continuous case, since it highlights that the important factor in \Cref{eq:utility_pm} is the distribution on patches $p_i$.

In nature many habitats are continuous and cannot be described well as discrete patches, so our approach provides a way to resolve population games while keeping the continuous nature of the habitat.

To extend population games to continuous space and facilitate the incorporation of imperfect decision making, we consider a habitat described by an interval $[0,z_0]$. We again assume we have $T$ different types. Define the continuous analogue of the patch distribution $p_i$ by:
\begin{equation}
  K = \{ f \in L^2([0,z_0]) : f \geq 0,~\int f dz = 1\}
  \label{eq:space_of_dists}
\end{equation}
i.e. $K$ is the set of square-integrable probability distributions on $[0,z_0]$. The quantity $N_i \phi_i(z)$ gives the population of type $i$ at $z$. Interactions between animals of type $i$ and $j$ are given by bounded linear operators $U_{ij}: L^2([0,z_0]) \to L^2([0,z_0])$. A bounded linear operator on $L^2([0,z_0])$ can be thought of as an infinite-dimensional matrix. In case the interactions are local, the operators $U_{ij}$ reduce to multiplication by bounded functions, corresponding to diagonal matrices. This consideration explains why we require square-integrability, since we want to be able to consider purely local interactions. As in the finite case, we define the local intrinsic growth by a bounded function $G_i$. Using $G_i$, $K$, and $U_{ij}$ we can define the fitness proxy $F_i$ of an individual of type $i$ playing strategy $\phi_i$ in the continuous setting:
%\todo[inline]{Afhængigt af tidsskriftet bør vi overveje om det med $U$-operatoren skal gøres mere eksplicit.}
\begin{equation}
  F_i(\phi_i, (N_j \phi_j)_{j \leq T, j \neq i}) = \sum_{j=1,j\neq i}^T \int \phi_i(z) (U_{ij}N_j \phi_j)(z) dz + \int \phi_i(z) G_i(z) dz %, ~i\neq j~n_{ij}=1,~i=j~n_{ij} = \frac{1}{2}
  \label{eq:utility}
\end{equation}
The game given by maximizing all $F_i$ with respect to $\phi_i$ is the continuous analogue of a polymatrix game. Since the game again has polymorphic-monomorphic equivalence, the Nash equilibrium for the individual habitat selection game is also given by finding the Nash equilibrium of the game specified by \Cref{eq:utility}.

Modeling the population dynamics, we assume that at every instant the animals are distributed according to the Nash equilibrium of \Cref{eq:utility}. That is, no animal can increase their utility by unilaterally deviating from their strategy. Denoting the Nash equilibrium by $(\phi_i^{*,NE})^T_{i=1}$, the population dynamics are:
\begin{equation}
  \dot{N_i}((\phi_j^{*,NE})_{j=1}^T ) = N_i F_i((\phi_j^{*,NE}, N_j)_{j=1}^N)
\end{equation}

The model we use can theoretically be used for other situations than habitat-choice and population dynamics. As long as the population dynamics can be formulated in way where they are proportional to sums of bilinear payoffs in the strategies, our approach can be used.

%\todo[inline]{Udmærket struktur; skal bare gennemskrives en gang.}
%\todo[inline]{Gennemskrivning i gang; Færdig}


\subsubsection{Noisy strategies}
Our model incorporates that animals are not necessarily perfectly rational: The animal may not be a perfect decision-maker and may choose a slightly sub-optimal habitat, due to imperfect information or limited capacity of information processing, but it can also model errors in our perception of the animal's objectives, or inability to actuate a decision perfectly, for example due to turbulence in the water column. Our model of imperfect rationality is as follows: Say that an animal of type $i$ aims to play the strategy $f_i(\cdot)$, which is a probability density function on $[0,z_0]$. Then our model posits that the animal actually plays a strategy $\phi_i(\cdot ,\sigma)$, which is a smoothed version of $f_i(\cdot)$ obtained by solving the initial value problem
\begin{equation}
  \begin{split}
  \label{eq:density_PDE}
  \partial_s \phi_i &= \frac{1}{2}\partial_z^2 \phi_i \\
  \partial_z \phi_i \mid_{z=0} &= 0 \\
  \partial_z \phi_i \mid_{z = z_0} &= 0 \\
   \phi_i(z,0) &= f_i(z) \quad .
 \end{split}
\end{equation}
on the interval $[0,\sigma]$. Thus, the parameter $\sigma$ determines the degree of smoothing: With $\sigma=0$, the animal is perfectly rational ($\phi_i(z,0)=f_i(z)$) while with $\sigma=\infty$, we have a completely random decisions where $\phi_i(z,\infty)$ is a constant function of $z$, corresponding to a uniform distribution on $[0,z_0]$. Note that $s$ or $\sigma$ are not connected to time; this smoothing takes place instantaneously at each point in time.

Numerically, this smoothing is performed by first determining the fundamental solution to this initial value problem, ignoring boundaries, which is a Gaussian kernel. Then the boundary conditions are implemented using the method of images, resulting in a kernel $G(x)$. Finally, the initial condition is convolved with $G(x)$ kernel.


\subsubsection{Spatial discretization}
In order to calculate the Nash Equilibrium efficiently, and perform numerical integration precisely we discretize the interval $[0,z_0]$ with a spectral scheme based on Legendre polynomials, \citep{kopriva2009implementing}. This allows precise integration and differentation of piece-wise smooth functions with only relatively few points. Working on a grid with $M$ points, a strategy is a linear combination of normalized hat-functions, where the hat functions are given by:
\begin{align*}
	& \int_{z_{i-1}}^{z_{i+1}} e_i dz = 1 \\
	&e_i(z_{i-1}) = 0,~ e_i(z_{i+1}) = 0
\end{align*}
where the overall strategy becomes:
\begin{align*}
  &\phi_{i} = \sum_{j=1}^M a_{j,i} e_j, \quad i\in \{1,\dots, N\} \\
  &\sum_{j=1}^M a_{j,i} = 1 \quad i\in \{1,\dots, N\}
\end{align*}
The strategy of a player, or type, is fully determined by the $a_i$'s.


When considering non-optimal actors, we need to implement the convolution with $G(x)$, which also assures that the resulting distribution is smooth. An added benefit of incorporating bounded rationality then becomes that our strategy profiles are guaranteed to be smooth, decreasing the number of points required for numerically exact evaluation of the integrals determining the fitness \Cref{eq:utility}.


\subsubsection{Finding the Nash Equilibrium}
Finding the Nash Equilibrium in a game in continuous space is usually a hard task, requiring the development of bespoke methods, \citep{verticalmigration, jerome}. We develop a general method which does not rely on the specific structure of the interactions or habitat, by combining a result on linear complementarity problems \citep{miller1991copositive} with an efficient solver.

By discretizing space, we have reduced an uncountable strategy set to a more manageable finite set, with pure strategies $e_k$. The gain of type $k$ playing strategy $e_k$ against type $j$ playing strategy $e_l$ can be determined as $U_{ij}(e_k,e_l)$, \Cref{eq:utility}. Evaluating these integrals reduces the continuous game to a discrete habitat choice game \Cref{utility_pm} with payoff matrices $A_{ij}$ determined through the numerical integration $A_{ij}(k,l)=\ip{e_k}{U_{ij}e_l}, k,l \in \{1,\dots M\}$.
Our discretization has reduced the problem to a polymatrix game, where finding the Nash equilibrium is tractable.

It does not appear to have diffused through the literature, but a Nash equilibrium of a polymatrix game can be found by solving a single linear complementarity problem \citep{miller1991copositive}. We give a short proof of this using using a modification of the argument from \citep{miller1991copositive}, specialized to the case of two-player (bimatrix) games but easily generalizable to the general $N$-player case. Assume that $(s^*_1,s^*_2)$ constitute a Nash equilibrium in mixed strategies with values $\gamma_1 = \ip{s^*_1}{E_1 s^*_2}$ and  $\gamma_2 = \ip{s^*_2}{E_2 s^*_1}$ to the first and second player, respectively. Then
\[
  \ip{s_1}{1_n} =
  \ip{s_2}{1_n} =
  1
\]
since these mixed strategies are probability distributions on strategy space. Here $1_n$ is a vector of ones. In addition the Nash equilibrium dictates
\[
  E_1 s_2 = 1_n \gamma_1 - w_1
  ,\quad
  E_2 s_1 = 1_n \gamma_2  - w_2
\]
$w_1$ and $w_2$ are non-negative ``slack variables'' that state that the payoff for the first player can be no greater than the expected payoff $\gamma_1$, but can be smaller for some fixed strategies. These non-optimal strategies, where the slack $w_1$ is positive, must then be chosen with probability 0, and as a consequence the complementarity condition
\[
  \ip{s^*_1}{w_1} =   \ip{s^*_2}{w_2} = 0
\]
holds. Assume for convenience that all elements in $E_1$ and $E_1$ are negative; this can always be obtained without changing the Nash equilibrium by subtracting a constant from $E_1$ and $E_2$. Consequenty, the payoffs $\gamma_1$ and $\gamma_2$ are also negative and thus the vector $z = (s_1,s_2,-\gamma_1,-\gamma_2)$ satisfies the Linear Complementarity Problem (LCP)
\begin{equation}
  z \geq 0,
  w \geq 0 ,
  H
  z
  +
  \left(
    \begin{array}{c}
      0 \\
      0 \\
      -1 \\
      -1
    \end{array}
  \right)
  =
  w
  ,
  \quad
  \ip{z}{w} = 0
  .  \label{eq:lcp}
\end{equation}
where
\[
  H =
  \left[
    \begin{array}{cccc}
      0 & -E_1 & -1_n & 0 \\ -E_2 & 0 & 0 & -1_n \\
      1_n & 0 & 0 & 0 \\
      0 & 1_n & 0 & 0
    \end{array}
  \right]
\]
Conversely, assume that $z=(s_1,s_2,\gamma_1,\gamma_2)$ and $w$ solve the Linear Complementarity Problem, then it is straightforward to see that the mixed strategies $(s_1,s_2)$ form a Nash equilibrium with values $(\gamma_1,\gamma_2)$. The assumption that $E_1$ and $E_2$ have negative elements imply that the matrix $H$ is copositive plus (meaning, for all $z\geq0$ with $z\neq0$ it holds that $\ip z{Hz}>0$) which assures that the LCP to has a solution, in particular through Lemke's algorithm.

Solving \Cref{eq:lcp} was done through two different methods. The interior-point method as implemented in IPOPT, \citep{wachter2006implementation}, called via. the auto-differentation software CasADi \citep{Andersson2019}, and Lemkes Algorithm implemented in the Numerics package in Siconos, \citep{acary2019introduction}. Experience showed that Lemkes algorithm was the fastest.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
