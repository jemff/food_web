\section{Method}

\subsection{General continuous model and the discrete motivation}
\label{sec:gen_model}

Our general model is that of a population-game \citep{kvrivan2009evolutionary} where the populations can migrate in a continuous habitat on a much faster time-scale than population dynamics \citep{cressman2006migration}. We start by building up the general approach in a discrete setting, and then translate the structures we have built up into the continuous setting.

\subsubsection{Developing a discrete population game}
To understand the intrinsic coupling of patch-choice models with population dynamics, consider start by considering a Lotka-Volterra model with $M$ patches and $T$ types. Assume the interactions of animals of type $i$ with type $j$ at patches $k$ and $l$ is given by a matrix $A_{ij}(k,l)$. The intrinsic growth of type $i$ at patch $k$ is given by a function $G_{i}(k)$ on $\{1,\dots,M\}$. Assuming that the populations are distributed according to probability distributions $(p_i)_{i=1}^T$ on the patches $\{1,\ldots,M\}$. The population dynamics of type $i$ with total abundance $N_i$ become:
  \begin{equation}
  \dot{N}_i = N_i \sum_{k=1}^M p_i(k) \pa{\sum_{j=1}^T {(N_j A_{ij} p_j)}(k) + G_i(k)}
  \label{eq:pop_dyn_lv}
\end{equation}
We define the fitness proxy for an individual of type $i$ at patch $k$ by $H_i(k)$, as the growth of an individual of type $i$ at patch $k$ given that all types are distributed according to $(p_i)_{i=1}^T$.
\begin{equation}
  H_i((N_j p_j)_{j=1}^T)(k) = \pa{\sum_{j=1}^T (N_j A_{ij}p_j)(k)} + G_i(k)%
  \label{eq:utility_pm}
\end{equation}
If migrations are very fast and the habitat is highly interconnected \citep{cressman2006migration, abrams2007role}, it is reasonable to assume all animals of any type simultaneously seek to find the optimum patch in the sense of seeking $k$ to maximize \Cref{eq:utility_pm}. In a single-species case, the resulting patch distribution $p^*$ is the ideal free distribution \citep{fretwell1969territorial}. At the Nash equilibrium, the payoff $H_i((N_j p_j^*)_{j=1}^T)(k)$ is constant except where $p_i(k)$ is zero. The approach of using population dynamics determined by \Cref{eq:pop_dyn_lv} with optimal strategies determined by the Nash equilibrium defines a population game on discrete patches, and is a successful approach to coupling optimal behavior with population dynamics \citep{valdovinos2010consequences, mougi2019adaptive, pinti2021co}.


%In the polymorphic game \Cref{eq:utility_pm} \todo{Jeg forstår ikke denne henvisning} if an individual of type $i$ at patch $k$ interacts with other individuals of type $i$ each individual gets equal payoff, corresponding to the monomorphic population getting half \todo{Dette er uklart, og jeg er ikke sikker på at jeg er enig i fortolkningen.} the payoff \citep{kvrivan2008ideal, eaves1973polymatrix}.
%The interpretation comes from noting that $H_i$ is affine in $p_j$ and independent of $p_i$, so the sum of the payoff at all patches can be written as
%\begin{equation}%
 %\ip{p_i}{H_i((N_j p_j)_{j=1}^T)} = \ip{p_i}{\pa{\sum_{j=1}^T (N_j A_{ij}p_j)(k)} + G_i(k)}%
%\end{equation}


If we assume that $A_{ii}=0$ for all $i$, the problem of finding the Nash equilibrium $(p_i^{*,NE})_{i=1}^T$ of the game specified by all $H_i$ in \Cref{eq:utility_pm} can be interpreted as finding the Nash equilibrium in a polymatrix game \citep{howson1972equilibria, eaves1973polymatrix}. A polymatrix game has so-called polymorphic-monomorphic equivalence \citep{broom2013game, eaves1973polymatrix}, so an individual of type $j$ cannot determine whether it is playing against a polymorphic population $i$ with pure strategies, or a monomorphic population with a mixed strategy. The monomorphic interpretation is that we assume that all individuals of type $i$ choose their positions randomly according to the distribution $p_i$, instead of having players pick fixed position $p_i(k)$. Finding the Nash equilibrium $(p_i)^{*,NE}$ of \Cref{eq:utility_pm} is then equivalent to finding the Nash equilibrium of the game:
\begin{equation}
  \label{eq:poly_fitness}
  F_i(p_i, (N_j p_j)_{j=1}^T) = \ip{p_i}{\sum_{j=1}^T E_{ij} p_j}
\end{equation}
Where we let $\Gamma_i$ be matrix where every column is $G_i$, so that $(\Gamma_i p_j)(k) = G(k)$. The total payoff matrices $E_{ij}$ for the interaction between type $i$ and $j$ then become:
\begin{equation}
  \label{eq:disc_tot_payoff}
  \begin{split}
  \Gamma_i(l,k) = G_i(k) \\
    E_{ij} = N_j A_{ij} + \frac{1}{T}\Gamma_i%, \quad v_{ij}=1,i\neq j,~v_{ij}=\frac{1}{2},i=i, v_{ij}
  \end{split}
\end{equation}
%\todo[inline]{Jeg forstår overhovedet ikke det foregående. Slutresultatet, derimod, er klart, altså at ligning (2) kan skrives på en matriksform. Så for mig ville det være lettere at vende den om: Starte med at konstatere at $H_i(k)$ er affin i $p$ og dermed kan skrives på en matriksform, angive den generelle form af denne, d.v.s. (4), og så til sidst fedte kooefficienterne på plads. I øvrigt forstår jeg heller ikke her notationen på venstresiden af (4).}

%with $A_{ii}$ scaled by $\frac{1}{2}, but otherwise subtly different
%In the case where \Cref{eq:utility_pm} has no density dependence

We recognize \Cref{eq:poly_fitness} as the growth rate in \Cref{eq:pop_dyn_lv}. Therefore, optimizing the population growth per type and at the individual level are the same when there is no density dependence $(A_{ii}=0)$. Following the Nash equilibrium of the game \Cref{eq:poly_fitness} at every instant is an evolutionary stable strategy, i.e. the populations cannot be invaded by mutants \citep{kvrivan2009evolutionary}. These considerations resolve the discrete case, but in nature many habitats are continuous and cannot be described well as discrete patches. However, having a fully-developed discrete model sets the stage for the continuous generalization, and lets use the ideas for constructing a population game in continuous space.

\subsubsection{The continuous model}
The insight of using the monomorphic-polymorphic equivalence is essential in generalizing to the continuous case, since it highlights that the important factor in the individual patch choice \Cref{eq:utility_pm} is the overall distribution on patches $p_i$. To extend population games to continuous space and facilitate the incorporation of imperfect decision making, we consider a habitat described by an interval $[0,z_0]$. We again assume we have $T$ different types. Define the continuous analogues of patch distribution by:
\begin{equation}
  K = \{ \phi \in L^2([0,z_0]) : \phi \geq 0,~\int \phi dz = 1\}
  \label{eq:space_of_dists}
\end{equation}
i.e. $K$ is the set of square-integrable probability distributions on $[0,z_0]$, and $\phi_i \in K$ corresponds to a patch distribution $p_i$. The quantity $N_i \phi_i(z)$ gives the population of type $i$ at $z$. Interactions between animals of type $i$ and $j$ are given by bounded linear operators $U_{ij}: L^2([0,z_0]) \to L^2([0,z_0])$. A bounded linear operator on $L^2([0,z_0])$ can be thought of as an infinite-dimensional matrix. In case the interactions are local, the operators $U_{ij}$ reduce to multiplication by bounded functions, corresponding to diagonal matrices. This consideration explains why we require square-integrability, since we want to be able to consider purely local interactions. As in the discrete case, we define the local intrinsic growth by a bounded function $B_i$. Using $B_i$, $K$, and $U_{ij}$ we can define the fitness proxy $F_i$ of an individual of type $i$ playing strategy $\phi_i$ in the continuous setting:
%\todo[inline]{Afhængigt af tidsskriftet bør vi overveje om det med $U$-operatoren skal gøres mere eksplicit.}
\begin{equation}
  F_i(\phi_i, (N_j \phi_j)_{j=1}^T = \sum_{j=1}^T \int \phi_i(z) (U_{ij}N_j \phi_j)(z) dz + \int \phi_i(z) G_i(z) dz %, ~i\neq j~n_{ij}=1,~i=j~n_{ij} = \frac{1}{2}v_{ij} \frac{1}{v_{ij}}
  \label{eq:utility}
\end{equation}
The game given by maximizing all $F_i$ with respect to $\phi_i$ is the continuous analogue of a polymatrix game. Since the game again has polymorphic-monomorphic equivalence, the Nash equilibrium for the individual habitat selection game is also given by finding the Nash equilibrium of the game specified by \Cref{eq:utility}.

Modeling the population dynamics, we assume that at every instant the animals are distributed according to the Nash equilibrium of \Cref{eq:utility}. That is, no animal can increase their utility by unilaterally deviating from their strategy. Denoting the Nash equilibrium by $(\phi_i^{*,NE})^T_{i=1}$, the population dynamics are:
\begin{equation}
  \dot{N_i}((\phi_j^{*,NE})_{j=1}^T ) = N_i F_i((\phi_j^{*,NE},N_j)_{j=1}^N)
\end{equation}

The model we use can theoretically be used for other situations than habitat-choice and population dynamics. As long as the population dynamics can be formulated in way where they are proportional to sums of bilinear payoffs in the strategies, our approach can be used.

%\todo[inline]{Udmærket struktur; skal bare gennemskrives en gang.}
%\todo[inline]{Gennemskrivning i gang; Færdig}


\subsubsection{Noisy strategies}
Our model incorporates that animals are not necessarily perfectly rational: The animal may not be a perfect decision-maker and may choose a slightly sub-optimal habitat, due to imperfect information or limited capacity of information processing, but it can also model errors in our perception of the animal's objectives, or inability to actuate a decision perfectly, for example due to turbulence in the water column. Our model of imperfect rationality is as follows: Say that an animal of type $i$ aims to play the strategy $f_i(\cdot)$, which is a probability density function on $[0,z_0]$. Then our model posits that the animal actually plays a strategy $\phi_i(\cdot ,\sigma)$, which is a smoothed version of $f_i(\cdot)$ obtained by solving the initial value problem
\begin{equation}
  \begin{split}
  \label{eq:density_PDE}
  \partial_s \phi_i &= \frac{1}{2}\partial_z^2 \phi_i \\
  \partial_z \phi_i \mid_{z=0} &= 0 \\
  \partial_z \phi_i \mid_{z = z_0} &= 0 \\
   \phi_i(z,0) &= f_i(z) \quad .
 \end{split}
\end{equation}
on the interval $[0,\sigma]$. Thus, the parameter $\sigma$ determines the degree of smoothing: With $\sigma=0$, the animal is perfectly rational ($\phi_i(z,0)=f_i(z)$) while with $\sigma=\infty$, we have a completely random decisions where $\phi_i(z,\infty)$ is a constant function of $z$, corresponding to a uniform distribution on $[0,z_0]$. Note that $s$ or $\sigma$ are not connected to time; this smoothing takes place instantaneously at each point in time.

Numerically, this smoothing is performed by first determining the fundamental solution to this initial value problem, ignoring boundaries, which is a Gaussian kernel. Then the boundary conditions are implemented using the method of images, resulting in a kernel $S(x)$. Finally, the initial condition is convolved with the kernel $S(x)$.


\subsubsection{Spatial discretization}
In order to calculate the Nash Equilibrium efficiently, and perform numerical integration precisely we discretize the interval $[0,z_0]$ with a spectral scheme based on Legendre polynomials, \citep{kopriva2009implementing}. This allows precise integration and differentation of piece-wise smooth functions with only relatively few points. Working on a grid with $M$ points, a strategy is a linear combination of normalized hat-functions, where the hat functions are given by:
\begin{align*}
	& \int_{z_{i-1}}^{z_{i+1}} e_i dz = 1 \\
	&e_i(z_{i-1}) = 0,~ e_i(z_{i+1}) = 0
\end{align*}
where the overall strategy becomes:
\begin{align*}
  &\phi_{i} = \sum_{j=1}^M a_{j,i} e_j, \quad i\in \{1,\dots, N\} \\
  &\sum_{j=1}^M a_{j,i} = 1 \quad i\in \{1,\dots, N\}
\end{align*}
The strategy of a player, or type, is fully determined by the $a_i$'s.


When considering non-optimal actors, we need to implement the convolution with $G(x)$, which also assures that the resulting distribution is smooth. An added benefit of incorporating bounded rationality then becomes that our strategy profiles are guaranteed to be smooth, decreasing the number of points required for numerically exact evaluation of the integrals determining the fitness \Cref{eq:utility}.


\subsubsection{Finding the Nash Equilibrium}
Finding the Nash Equilibrium in a game in continuous space is usually a hard task, requiring the development of bespoke methods, \citep{verticalmigration, jerome}. We develop a general method which does not rely on the specific structure of the interactions or habitat, by combining a result on linear complementarity problems \citep{miller1991copositive} with an efficient solver.

By discretizing space, we have reduced an uncountable strategy set to a more manageable finite set, with pure strategies $e_k$. The gain of type $k$ playing strategy $e_k$ against type $j$ playing strategy $e_l$ can be determined as $U_{ij}(e_k,e_l)$, \Cref{eq:utility}. Evaluating these integrals reduces the continuous game to a discrete habitat choice game \Cref{utility_pm} with payoff matrices $A_{ij}$ determined through the numerical integration $A_{ij}(k,l)=\ip{e_k}{U_{ij}e_l}, k,l \in \{1,\dots M\}$. The location-specific growth is discretized by defining $G_i(k) = \int B_i(z) e_k(z) dz$. We construct the total payoff matrices $E_{ij}$ for the game between types $i$ and $j$ as in the discrete case \Cref{eq:disc_tot_payoff}.

Our discretization has reduced the problem to a polymatrix game, where finding the Nash equilibrium is tractable.

It does not appear to have diffused through the literature, but a Nash equilibrium of a polymatrix game can be found by solving a single linear complementarity problem \citep{miller1991copositive}. We give a short proof of this using using a modification of the argument from \citep{miller1991copositive}, specialized to the case of two-player (bimatrix) games but easily generalizable to the general $T$-player case. Assume that $(s^*_1,s^*_2)$ constitute a Nash equilibrium in mixed strategies with values $\gamma_1 = \ip{s^*_1}{E_1 s^*_2}$ and  $\gamma_2 = \ip{s^*_2}{E_2 s^*_1}$ to the first and second player, respectively. Then
\[
  \ip{s_1}{1_n} =
  \ip{s_2}{1_n} =
  1
\]
since these mixed strategies are probability distributions on strategy space. Here $1_n$ is a vector of ones. In addition the Nash equilibrium dictates
\[
  E_1 s_2 = 1_n \gamma_1 - w_1
  ,\quad
  E_2 s_1 = 1_n \gamma_2  - w_2
\]
$w_1$ and $w_2$ are non-negative ``slack variables'' that state that the payoff for the first player can be no greater than the expected payoff $\gamma_1$, but can be smaller for some fixed strategies. These non-optimal strategies, where the slack $w_1$ is positive, must then be chosen with probability 0, and as a consequence the complementarity condition
\[
  \ip{s^*_1}{w_1} = \ip{s^*_2}{w_2} = 0
\]
holds. Assume for convenience that all elements in $E_1$ and $E_1$ are negative; this can always be obtained without changing the Nash equilibrium by subtracting a constant from $E_1$ and $E_2$. Consequenty, the payoffs $\gamma_1$ and $\gamma_2$ are also negative and thus the vector $z = (s_1,s_2,-\gamma_1,-\gamma_2)$ satisfies the Linear Complementarity Problem (LCP)
\begin{equation}
  z \geq 0,
  w \geq 0 ,
  H
  z
  +
  \left(
    \begin{array}{c}
      0 \\
      0 \\
      -1 \\
      -1
    \end{array}
  \right)
  =
  w
  ,
  \quad
  \ip{z}{w} = 0
  .  \label{eq:lcp}
\end{equation}
where
\[
  H =
  \left[
    \begin{array}{cccc}
      0 & -E_1 & -1_n & 0 \\ -E_2 & 0 & 0 & -1_n \\
      1_n & 0 & 0 & 0 \\
      0 & 1_n & 0 & 0
    \end{array}
  \right]
\]
Conversely, assume that $z=(s_1,s_2,\gamma_1,\gamma_2)$ and $w$ solve the Linear Complementarity Problem, then it is straightforward to see that the mixed strategies $(s_1,s_2)$ form a Nash equilibrium with values $(\gamma_1,\gamma_2)$. The assumption that $E_1$ and $E_2$ have negative elements imply that the matrix $H$ is copositive plus (meaning, for all $z\geq0$ with $z\neq0$ it holds that $\ip z{Hz}>0$) which assures that the LCP to has a solution, in particular through Lemke's algorithm.

Solving \Cref{eq:lcp} was done through two different methods. The interior-point method as implemented in IPOPT, \citep{wachter2006implementation}, called via. the auto-differentation software CasADi \citep{Andersson2019}, and Lemkes Algorithm implemented in the Numerics package in Siconos, \citep{acary2019introduction}. Experience showed that Lemkes algorithm was the fastest.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
