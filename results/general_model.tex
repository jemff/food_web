\section{Method}
\subsection*{General model framework}

The basic structure in the games we study is a system of $N$ players, with strategies given by probability distributions $\phi_i$ on a space $X$, henceforth an interval $[0,z_0]$. The payoffs $U_i$ of the players are given by matrices, or, in the continuous setting, linear operators $U_ij$ as

\begin{equation}
  \label{eq:utility}
  U_i = \sum_{j=1,j\neq i}^N \int n_{ij}\phi_i U_{ij} \phi_j dx%, ~i\neq j~n_{ij}=1,~i=j~n_{ij} = \frac{1}{2}
\end{equation}
We can see that this generalizes the notion of a polymatrix game, if the integral is replaced by a sum and the probability distributions are replaced by strategy vectors. The population dynamical systems that can be modelled via. games like this are where the population dynamics of species $i$ can be modelled as
\begin{equation}
  \dot{N_i} = N_i U_i
\end{equation}

In a polymatrix population game, there is polymorphic-monomorphic equivalence \citep{broom2013game}, so an individual of type $j$ cannot distinguish whether an opposing population playing a mixed strategy $\phi$ is a mixture of individuals playing pure strategies, or all individuals play a single mixed strategy. As such, our approach entails each individual in a species or population making optimal choices, and the other groups reacting to the total choice.

The Nash equilibrium of such a system consists of a family of probability distributions $(\phi_i^{*,NE})_{i=1}^N$ where no player can increase their utility by unilaterally deviating from their strategy.% An example of such a game is a habitat selection game, where picking the strategy that maximizes the instantaneous growth gives rise to an ESS \citep{kvrivan2009}.

\subsubsection*{Noisy strategies}
Our model incorporates that players are not necessarily perfectly rational: The player may not be a perfect decision-maker, due to imperfect information or limited capacity of information processing, but it can also model errors in our perception of the player's objectives, or inability to actuate a decision perfectly, for example due to turbulence in the water column. Our model of imperfect rationality is as follows: Say that the player aims to play the strategy $f_X(\cdot)$, which is a probability density function on $[0,z_0]$. Then our model posits that the player actually plays a strategy $\phi_i(\cdot ,\sigma)$, which is a smoothed version of $f_X(\cdot)$ obtained by solving the initial value problem
\begin{align}
  \label{eq:density_PDE}
  &\partial_s \phi_i = \frac{1}{2}\partial_z^2 \phi_i \\
  &\partial_z \phi_i \mid_{z=0} = 0 \\
  &\partial_z \phi_i \mid_{z = z_0} = 0 \\
  & \phi_i(z,0) = f_X(z) \quad .
\end{align}
on the interval $[0,\sigma]$. Thus, the parameter $\sigma$ determines the degree of smoothing: With $\sigma=0$, the player is perfectly rational ($\phi_i(z,0)=f_X(z)$) while with $\sigma=\infty$, we have a completely random decisions where $\phi_i(z,\infty)$ is a constant function of $z$, corresponding to a uniform distribution on $[0,z_0]$. Note that $s$ or $\sigma$ are not connected to time; this smoothing takes place instantaneously at each point in time.

Numerically, this smoothing is performed by first determining the fundamental solution to this initial value problem, ignoring boundaries, which is a Gaussian kernel. Then the boundary conditions are implemented using the method of images. Finally, the initial condition is convolved with this kernel.


\subsubsection*{Spatial discretization}
In order to calculate the Nash Equilibrium efficiently, and perform numerical integration precisely we discretize the interval $[0,z_0]$ with a spectral scheme based on Legendre polynomials, \citep{kopriva2009implementing}. This allows precise integration and differentation with only relatively few points.
We approximate pure strategy of being in a point $z_i$  by a normalized hat-function $e_i$, zero everywhere apart from $z_i$.
\begin{align*}
	& \int_{z_i}^{z_{i+1}} e_i dz = 1 \\
	&e_i(z_{i-1}) = 0,~ e_i(z_{i+1}) = 0
\end{align*}
Working on a grid with $M$ points, a strategy then becomes a linear combination of hat-functions,
\begin{align*}
  &\phi_{i} = \sum_{j<M} a_{j,i} e_j, \quad i\in \{1,\dots, N\} \\
  &\sum_{j<M} a_{j,i} = 1 \quad i\in \{1,\dots, N\}
\end{align*}
The strategy of a player is fully determined by the $a_i$'s.

When considering non-optimal actors, we need to implement the convolution with $f_Y$, which also assures that the resulting distrbution is smooth. An added benefit of incorporating bounded rationality then becomes that our strategy profiles are guaranteed to be smooth, decreasing the number of points needed for exact evaluation of the integrals.


\subsubsection*{Finding the Nash Equilibrium}
Finding the Nash Equilibrium in a game in continuous space is usually a hard task, requiring the development of bespoke methods, \citep{verticalmigration}, or very long runtimes, \citep{jerome}. The method we have use circumvents these problems, by combining a little-known result in mathematical optimization with a spectral scheme.

By discretizing space, we have reduced an uncountable strategy set to a more manageable finite amount, with pure strategies $e_k$. The gain of a player playing strategy $e_k$ against player $j$ playing strategy $e_l$ can be determined as $A_{ij}(e_k,e_l)$, \Cref{eq:utility}. The discretization allows us to write up payoffs for a finite approximation version of the continuous game,  with entry $(k,l)$ determined through $\ip{e_k}{A_{ij}e_l}, k,l \in \{1,\dots M\}$.
Our discretization has reduced the problem to a bimatrix game, where finding the Nash equilibrium is more tractable.

It does not appear to have diffused through the literature, but a Nash equilibrium of a polymatrix game can be found by solving a single linear complementarity problem \citep{miller1991copositive}. Using a modification of the argument from \citep{miller1991copositive}, specialized to the case of two-player (bimatrix) games but easily generalizable to the general $n$-player case. Assume that $(s^*_1,s^*_2)$ constitute a Nash equilibrium in mixed strategies with values $\gamma_1 = \ip{s^*_1}{E_1 s^*_2}$ and  $\gamma_2 = \ip{s^*_2}{E_2 s^*_1}$ to the consumer and predator, respectively. Then
\[
  \ip{s_1}{1_n} =
  \ip{s_2}{1_n} =
  1
\]
since these mixed strategies are probability distributions on strategy space. Here $1_n$ is a vector of ones. In addition the Nash equilibrium dictates
\[
  E_1 s_2 = 1_n \gamma_1 - w_1
  ,\quad
  E_2 s_1 = 1_n \gamma_2  - w_2
\]
$w_1$ and $w_2$ are non-negative ``slack variables'' that state that the payoff for the first player can be no greater than the expected payoff $\gamma_1$, but can be smaller for some fixed strategies. These non-optimal strategies, where the slack $w_1$ is positive, must then be chosen with probability 0, and as a consequence the complementarity condition
\[
  \ip{s^*_1}{w_1} =   \ip{s^*_2}{w_2} = 0
\]
holds. Assume for convenience that all elements in $E_1$ and $E_1$ are negative; this can always be obtained without changing the Nash equilibria by substracting a constant from $E_1$ and $E_2$. Consequenty, also the payoffs $\gamma_1$ and $\gamma_2$ are negative and thus the vector $z = (s_1,s_2,-\gamma_1,-\gamma_2)$ satisfies the Linear Complementarity Problem (LCP)
\[
\label{eq:lcp}
  z \geq 0,
  w \geq 0 ,
  H
  z
  +
  \left(
    \begin{array}{c}
      0 \\
      0 \\
      -1 \\
      -1
    \end{array}
  \right)
  =
  w
  ,
  \quad
  \ip{z}{w} = 0
  .
\]
where
\[
  H =
  \left[
    \begin{array}{cccc}
      0 & -E_1 & -1_n & 0 \\ -E_2 & 0 & 0 & -1_n \\
      1_n & 0 & 0 & 0 \\
      0 & 1_n & 0 & 0
    \end{array}
  \right]
\]
Conversely, assume that $z=(s_1,s_2,\gamma_1,\gamma_2)$ and $w$ solve the Linear Complementarity Problem, then it is straightforward to see that the mixed strategies $(s_1,s_2)$ form a Nash equilibrium with values $(\gamma_1,\gamma_2)$. The assumption that $E_1$ and $E_2$ have negative elements imply that the matrix $H$ is copositive plus (meaning, for all $z\geq0$ with $z\neq0$ it holds that $\ip z{Hz}>0$) which assures that the LCP to has a solution, in particular through Lemke's algorithm.

Solving \Cref{eq:lcp} was done through two different methods. The interior-point method as implemented in IPOPT, \citep{wachter2006implementation}, called via. the auto-differentation software CasADi \citep{Andersson2019}, and Lemkes Algorithm implemented in the Numerics package in Siconos, \citep{acary2019introduction}. Experience showed that Lemkes algorithm was the fastest.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
